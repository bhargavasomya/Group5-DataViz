{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "# Quora question pairs: training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "%matplotlib inline\nfrom __future__ import print_function\nimport numpy as np\nimport pandas as pd\nimport datetime, time, json\nfrom keras.models import Model\nfrom keras.layers import Input, TimeDistributed, Dense, Lambda, concatenate, Dropout, BatchNormalization\nfrom keras.layers.embeddings import Embedding\nfrom keras.regularizers import l2\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Initialize global variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": "Q1_TRAINING_DATA_FILE \u003d \u0027q1_train.npy\u0027\nQ2_TRAINING_DATA_FILE \u003d \u0027q2_train.npy\u0027\nLABEL_TRAINING_DATA_FILE \u003d \u0027label_train.npy\u0027\nWORD_EMBEDDING_MATRIX_FILE \u003d \u0027word_embedding_matrix.npy\u0027\nNB_WORDS_DATA_FILE \u003d \u0027nb_words.json\u0027\nMODEL_WEIGHTS_FILE \u003d \u0027question_pairs_weights_network1.h5\u0027\nMAX_SEQUENCE_LENGTH \u003d 25\nEMBEDDING_DIM \u003d 300\nVALIDATION_SPLIT \u003d 0.1\nTEST_SPLIT \u003d 0.1\nRNG_SEED \u003d 13371447\nNB_EPOCHS \u003d 25\nDROPOUT \u003d 0.1\nBATCH_SIZE \u003d 32"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Load the dataset, embedding matrix and word count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "q1_data \u003d np.load(open(Q1_TRAINING_DATA_FILE, \u0027rb\u0027))\n",
        "q2_data \u003d np.load(open(Q2_TRAINING_DATA_FILE, \u0027rb\u0027))\n",
        "labels \u003d np.load(open(LABEL_TRAINING_DATA_FILE, \u0027rb\u0027))\n",
        "word_embedding_matrix \u003d np.load(open(WORD_EMBEDDING_MATRIX_FILE, \u0027rb\u0027))\n",
        "with open(NB_WORDS_DATA_FILE, \u0027r\u0027) as f:\n",
        "    nb_words \u003d json.load(f)[\u0027nb_words\u0027]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Partition the dataset into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "X \u003d np.stack((q1_data, q2_data), axis\u003d1)\n",
        "y \u003d labels\n",
        "X_train, X_test, y_train, y_test \u003d train_test_split(X, y, test_size\u003dTEST_SPLIT, random_state\u003dRNG_SEED)\n",
        "Q1_train \u003d X_train[:,0]\n",
        "Q2_train \u003d X_train[:,1]\n",
        "Q1_test \u003d X_test[:,0]\n",
        "Q2_test \u003d X_test[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Define the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "question1 \u003d Input(shape\u003d(MAX_SEQUENCE_LENGTH,))\n",
        "question2 \u003d Input(shape\u003d(MAX_SEQUENCE_LENGTH,))\n",
        "\n",
        "#layer 1 for question 1 to convert the sequence of vectors into dense representation\n",
        "q1 \u003d Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights\u003d[word_embedding_matrix], \n",
        "                 input_length\u003dMAX_SEQUENCE_LENGTH, \n",
        "                 trainable\u003dFalse)(question1)\n",
        "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
        "q1 \u003d TimeDistributed(Dense(EMBEDDING_DIM, activation\u003d\u0027relu\u0027))(q1)\n",
        "q1 \u003d Lambda(lambda x: K.max(x, axis\u003d1), output_shape\u003d(EMBEDDING_DIM, ))(q1)\n",
        "\n",
        "#layer 1 for question 2 to convert the sequence of vectors into dense representation\n",
        "q2 \u003d Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights\u003d[word_embedding_matrix], \n",
        "                 input_length\u003dMAX_SEQUENCE_LENGTH, \n",
        "                 trainable\u003dFalse)(question2)\n",
        "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
        "q2 \u003d TimeDistributed(Dense(EMBEDDING_DIM, activation\u003d\u0027relu\u0027))(q2)\n",
        "q2 \u003d Lambda(lambda x: K.max(x, axis\u003d1), output_shape\u003d(EMBEDDING_DIM, ))(q2)\n",
        "\n",
        "#Concatenate the representations for question 1 and 2\n",
        "merged \u003d concatenate([q1,q2])\n",
        "\n",
        "#dense layer 1\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 2\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 3\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 4\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#final prediction using sigmoid activation\n",
        "is_duplicate \u003d Dense(1, activation\u003d\u0027sigmoid\u0027)(merged)\n",
        "\n",
        "model \u003d Model(inputs\u003d[question1,question2], outputs\u003dis_duplicate)\n",
        "model.compile(loss\u003d\u0027binary_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "input_9 (InputLayer)            (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           (None, 25)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_7 (Embedding)         (None, 25, 300)      28947900    input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_8 (Embedding)         (None, 25, 300)      28947900    input_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_7 (TimeDistrib (None, 25, 300)      90300       embedding_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_8 (TimeDistrib (None, 25, 300)      90300       embedding_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_7 (Lambda)               (None, 300)          0           time_distributed_7[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "lambda_8 (Lambda)               (None, 300)          0           time_distributed_8[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 600)          0           lambda_7[0][0]                   \n",
            "                                                                 lambda_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 200)          120200      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_13 (Dropout)            (None, 200)          0           dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 200)          800         dropout_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 200)          40200       batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_14 (Dropout)            (None, 200)          0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 200)          800         dropout_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 200)          40200       batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_15 (Dropout)            (None, 200)          0           dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 200)          800         dropout_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 200)          40200       batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_16 (Dropout)            (None, 200)          0           dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 200)          800         dropout_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 1)            201         batch_normalization_16[0][0]     \n",
            "\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\n",
            "Total params: 58,320,601\n",
            "Trainable params: 423,201\n",
            "Non-trainable params: 57,897,400\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Train the model, checkpointing weights with best validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training at 2019-03-28 01:08:24.731394\n",
            "Train on 327472 samples, validate on 36386 samples\n",
            "Epoch 1/25\n",
            " - 193s - loss: 0.4246 - acc: 0.7999 - val_loss: 0.4477 - val_acc: 0.7865\n",
            "Epoch 2/25\n",
            " - 209s - loss: 0.4075 - acc: 0.8106 - val_loss: 0.4368 - val_acc: 0.7887\n",
            "Epoch 3/25\n",
            " - 215s - loss: 0.3939 - acc: 0.8192 - val_loss: 0.4236 - val_acc: 0.7962\n",
            "Epoch 4/25\n",
            " - 208s - loss: 0.3813 - acc: 0.8259 - val_loss: 0.4166 - val_acc: 0.8009\n",
            "Epoch 5/25\n",
            " - 216s - loss: 0.3686 - acc: 0.8333 - val_loss: 0.4247 - val_acc: 0.7940\n",
            "Epoch 6/25\n",
            " - 214s - loss: 0.3584 - acc: 0.8389 - val_loss: 0.4220 - val_acc: 0.7993\n",
            "Epoch 7/25\n",
            " - 215s - loss: 0.3493 - acc: 0.8441 - val_loss: 0.4250 - val_acc: 0.7999\n",
            "Epoch 8/25\n",
            " - 213s - loss: 0.3423 - acc: 0.8481 - val_loss: 0.4153 - val_acc: 0.8042\n",
            "Epoch 9/25\n",
            " - 209s - loss: 0.3339 - acc: 0.8522 - val_loss: 0.4550 - val_acc: 0.7718\n",
            "Epoch 10/25\n",
            " - 212s - loss: 0.3286 - acc: 0.8557 - val_loss: 0.4155 - val_acc: 0.8055\n",
            "Epoch 11/25\n",
            " - 206s - loss: 0.3219 - acc: 0.8591 - val_loss: 0.4153 - val_acc: 0.8049\n",
            "Epoch 12/25\n",
            " - 209s - loss: 0.3181 - acc: 0.8610 - val_loss: 0.4358 - val_acc: 0.7982\n",
            "Epoch 13/25\n",
            " - 216s - loss: 0.3136 - acc: 0.8630 - val_loss: 0.4155 - val_acc: 0.8051\n",
            "Epoch 14/25\n",
            " - 215s - loss: 0.3085 - acc: 0.8656 - val_loss: 0.4271 - val_acc: 0.7983\n",
            "Epoch 15/25\n",
            " - 214s - loss: 0.3019 - acc: 0.8688 - val_loss: 0.4166 - val_acc: 0.8029\n",
            "Epoch 16/25\n",
            " - 213s - loss: 0.2996 - acc: 0.8698 - val_loss: 0.4261 - val_acc: 0.8065\n",
            "Epoch 17/25\n",
            " - 211s - loss: 0.2955 - acc: 0.8726 - val_loss: 0.4197 - val_acc: 0.8056\n",
            "Epoch 18/25\n",
            " - 211s - loss: 0.2900 - acc: 0.8756 - val_loss: 0.4193 - val_acc: 0.8031\n",
            "Epoch 19/25\n",
            " - 215s - loss: 0.2857 - acc: 0.8768 - val_loss: 0.4417 - val_acc: 0.8063\n",
            "Epoch 20/25\n",
            " - 210s - loss: 0.2829 - acc: 0.8784 - val_loss: 0.4192 - val_acc: 0.8097\n",
            "Epoch 21/25\n",
            " - 210s - loss: 0.2788 - acc: 0.8804 - val_loss: 0.4277 - val_acc: 0.8010\n",
            "Epoch 22/25\n",
            " - 212s - loss: 0.2764 - acc: 0.8812 - val_loss: 0.4303 - val_acc: 0.8071\n",
            "Epoch 23/25\n",
            " - 212s - loss: 0.2715 - acc: 0.8838 - val_loss: 0.4349 - val_acc: 0.8025\n",
            "Epoch 24/25\n",
            " - 216s - loss: 0.2692 - acc: 0.8849 - val_loss: 0.4352 - val_acc: 0.7987\n",
            "Epoch 25/25\n",
            " - 212s - loss: 0.2633 - acc: 0.8870 - val_loss: 0.4215 - val_acc: 0.8068\n",
            "Training ended at 2019-03-28 02:36:51.479775\n",
            "Minutes elapsed: 88.445806\n"
          ]
        }
      ],
      "source": [
        "print(\"Starting training at\", datetime.datetime.now())\n",
        "t0 \u003d time.time()\n",
        "\n",
        "#callback to store the best weights\n",
        "callbacks \u003d [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor\u003d\u0027val_acc\u0027, save_best_only\u003dTrue)]\n",
        "\n",
        "history \u003d model.fit([Q1_train, Q2_train],\n",
        "                    y_train,\n",
        "                    epochs\u003dNB_EPOCHS,\n",
        "                    validation_split\u003dVALIDATION_SPLIT,\n",
        "                    verbose\u003d2,\n",
        "                    batch_size\u003dBATCH_SIZE,\n",
        "                    callbacks\u003dcallbacks)\n",
        "t1 \u003d time.time()\n",
        "print(\"Training ended at\", datetime.datetime.now())\n",
        "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Plot training and validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\u003cmatplotlib.legend.Legend at 0x25c8efbd7b8\u003e"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "\u003cFigure size 432x288 with 1 Axes\u003e"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Data\n",
        "df\u003dpd.DataFrame({\u0027x\u0027: range(1,11), \u0027y1\u0027: np.random.randn(10), \u0027y2\u0027: np.random.randn(10)+range(1,11), \u0027y3\u0027: np.random.randn(10)+range(11,21) })\n",
        "acc \u003d pd.DataFrame({\u0027epoch\u0027: [ i + 1 for i in history.epoch ],\n",
        "                    \u0027training\u0027: history.history[\u0027acc\u0027],\n",
        "                    \u0027validation\u0027: history.history[\u0027val_acc\u0027]}) \n",
        "# multiple line plot\n",
        "ax\u003d plt.plot( \u0027epoch\u0027, \u0027training\u0027, data\u003dacc,markersize\u003d12, color\u003d\u0027blue\u0027, linewidth\u003d4)\n",
        "ax\u003d plt.plot( \u0027epoch\u0027, \u0027validation\u0027, data\u003dacc,markersize\u003d12, color\u003d\u0027red\u0027, linewidth\u003d4)\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Print best validation accuracy and epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum accuracy at epoch 22 \u003d 0.8086\n"
          ]
        }
      ],
      "source": [
        "max_val_acc, idx \u003d max((val, idx) for (idx, val) in enumerate(history.history[\u0027val_acc\u0027]))\n",
        "print(\u0027Maximum accuracy at epoch\u0027, \u0027{:d}\u0027.format(idx+1), \u0027\u003d\u0027, \u0027{:.4f}\u0027.format(max_val_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Evaluate the model with best validation accuracy on the test partition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": false,
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "model.load_weights(MODEL_WEIGHTS_FILE)\n",
        "loss, accuracy \u003d model.evaluate([Q1_test, Q2_test], y_test, verbose\u003d0)\n",
        "print(\u0027loss \u003d {0:.4f}, accuracy \u003d {1:.4f}\u0027.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Testing individual sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "### Use this section as a server for the Web Application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, TimeDistributed, dot, Dense, Lambda, Flatten, concatenate, Dropout, BatchNormalization\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.regularizers import l2\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "WORD_EMBEDDING_MATRIX_FILE \u003d \u0027word_embedding_matrix.npy\u0027\n",
        "NB_WORDS_DATA_FILE \u003d \u0027nb_words.json\u0027\n",
        "MODEL_WEIGHTS_FILE \u003d \u0027question_pairs_weights_network1.h5\u0027\n",
        "MAX_SEQUENCE_LENGTH \u003d 25\n",
        "EMBEDDING_DIM \u003d 300\n",
        "VALIDATION_SPLIT \u003d 0.1\n",
        "TEST_SPLIT \u003d 0.1\n",
        "RNG_SEED \u003d 13371447\n",
        "NB_EPOCHS \u003d 25\n",
        "DROPOUT \u003d 0.1\n",
        "BATCH_SIZE \u003d 32\n",
        "\n",
        "with open(NB_WORDS_DATA_FILE, \u0027r\u0027) as f:\n",
        "    nb_words \u003d json.load(f)[\u0027nb_words\u0027]\n",
        "    \n",
        "word_embedding_matrix \u003d np.load(open(WORD_EMBEDDING_MATRIX_FILE, \u0027rb\u0027))\n",
        "\n",
        "with open(\u0027word_index.pickle\u0027, \u0027rb\u0027) as handle:\n",
        "    word_indices \u003d pickle.load(handle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "question1 \u003d Input(shape\u003d(MAX_SEQUENCE_LENGTH,))\n",
        "question2 \u003d Input(shape\u003d(MAX_SEQUENCE_LENGTH,))\n",
        "\n",
        "#layer 1 for question 1 to convert the sequence of vectors into dense representation\n",
        "q1 \u003d Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights\u003d[word_embedding_matrix], \n",
        "                 input_length\u003dMAX_SEQUENCE_LENGTH, \n",
        "                 trainable\u003dFalse)(question1)\n",
        "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
        "q1 \u003d TimeDistributed(Dense(EMBEDDING_DIM, activation\u003d\u0027relu\u0027))(q1)\n",
        "q1 \u003d Lambda(lambda x: K.max(x, axis\u003d1), output_shape\u003d(EMBEDDING_DIM, ))(q1)\n",
        "\n",
        "#layer 1 for question 2 to convert the sequence of vectors into dense representation\n",
        "q2 \u003d Embedding(nb_words + 1, \n",
        "                 EMBEDDING_DIM, \n",
        "                 weights\u003d[word_embedding_matrix], \n",
        "                 input_length\u003dMAX_SEQUENCE_LENGTH, \n",
        "                 trainable\u003dFalse)(question2)\n",
        "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
        "q2 \u003d TimeDistributed(Dense(EMBEDDING_DIM, activation\u003d\u0027relu\u0027))(q2)\n",
        "q2 \u003d Lambda(lambda x: K.max(x, axis\u003d1), output_shape\u003d(EMBEDDING_DIM, ))(q2)\n",
        "\n",
        "#Concatenate the representations for question 1 and 2\n",
        "merged \u003d concatenate([q1,q2])\n",
        "\n",
        "#dense layer 1\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 2\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 3\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#dense layer 4\n",
        "merged \u003d Dense(200, activation\u003d\u0027relu\u0027)(merged)\n",
        "#to avoid overfitting\n",
        "merged \u003d Dropout(DROPOUT)(merged)\n",
        "merged \u003d BatchNormalization()(merged)\n",
        "\n",
        "#final prediction using sigmoid activation\n",
        "is_duplicate \u003d Dense(1, activation\u003d\u0027sigmoid\u0027)(merged)\n",
        "\n",
        "model \u003d Model(inputs\u003d[question1,question2], outputs\u003dis_duplicate)\n",
        "model.compile(loss\u003d\u0027binary_crossentropy\u0027, optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss \u003d 0.4180, accuracy \u003d 0.8118\n"
          ]
        }
      ],
      "source": [
        "model.load_weights(MODEL_WEIGHTS_FILE)\n",
        "loss, accuracy \u003d model.evaluate([Q1_test, Q2_test], y_test, verbose\u003d0)\n",
        "print(\u0027loss \u003d {0:.4f}, accuracy \u003d {1:.4f}\u0027.format(loss, accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [],
      "source": [
        "def word2vec(question):\n",
        "    word_seq \u003d keras.preprocessing.text.text_to_word_sequence(question)\n",
        "    \n",
        "    vec_sequence \u003d [word_indices[w] for w in word_seq]\n",
        "    \n",
        "    vec_sequence \u003d pad_sequences([vec_sequence], maxlen\u003d 25)\n",
        "    return vec_sequence\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "pycharm": {}
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00376096]], dtype\u003dfloat32)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question1 \u003d \u0027Hi the basketball league is fraud?\u0027\n",
        "question2 \u003d \u0027Hi what era is this?\u0027\n",
        "\n",
        "model.load_weights(MODEL_WEIGHTS_FILE)\n",
        "predictions \u003d model.predict([word2vec(question1), word2vec(question2)], verbose\u003d0)\n",
        "\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}