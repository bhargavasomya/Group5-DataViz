{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora question pairs: training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime, time, json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, dot, Dense, Lambda, Flatten, concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_TRAINING_DATA_FILE = 'q1_train.npy'\n",
    "Q2_TRAINING_DATA_FILE = 'q2_train.npy'\n",
    "LABEL_TRAINING_DATA_FILE = 'label_train.npy'\n",
    "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_network2.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset, embedding matrix and word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_data = np.load(open(Q1_TRAINING_DATA_FILE, 'rb'))\n",
    "q2_data = np.load(open(Q2_TRAINING_DATA_FILE, 'rb'))\n",
    "labels = np.load(open(LABEL_TRAINING_DATA_FILE, 'rb'))\n",
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    nb_words = json.load(f)['nb_words']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((q1_data, q2_data), axis=1)\n",
    "y = labels\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RNG_SEED)\n",
    "Q1_train = X_train[:,0]\n",
    "Q2_train = X_train[:,1]\n",
    "Q1_test = X_test[:,0]\n",
    "Q2_test = X_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "#layer 1 for question 1 to convert the sequence of vectors into dense representation\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
    "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "#layer 1 for question 2 to convert the sequence of vectors into dense representation\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
    "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "#Concatenate the representations for question 1 and 2\n",
    "merged = concatenate([q1,q2])\n",
    "\n",
    "#dense layer 1\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 2\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 3\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 4\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 5\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 6\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "\n",
    "#final prediction using sigmoid activation\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 25)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 300)      28947900    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 300)      28947900    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 25, 300)      90300       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 25, 300)      90300       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 300)          0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 300)          0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 600)          0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 200)          120200      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 200)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 200)          800         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 200)          40200       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 200)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 200)          800         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 200)          40200       batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 200)          800         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 200)          40200       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 200)          800         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 200)          40200       batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 200)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 200)          800         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 200)          40200       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 200)          0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 200)          800         dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            201         batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 58,402,601\n",
      "Trainable params: 504,401\n",
      "Non-trainable params: 57,898,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model, checkpointing weights with best validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training at 2019-03-25 20:48:08.024630\n",
      "Train on 327472 samples, validate on 36386 samples\n",
      "Epoch 1/25\n",
      " - 211s - loss: 0.5480 - acc: 0.7215 - val_loss: 0.4958 - val_acc: 0.7497\n",
      "Epoch 2/25\n",
      " - 232s - loss: 0.4929 - acc: 0.7571 - val_loss: 0.4773 - val_acc: 0.7614\n",
      "Epoch 3/25\n",
      " - 245s - loss: 0.4672 - acc: 0.7739 - val_loss: 0.4624 - val_acc: 0.7715\n",
      "Epoch 4/25\n",
      " - 251s - loss: 0.4448 - acc: 0.7880 - val_loss: 0.4568 - val_acc: 0.7747\n",
      "Epoch 5/25\n",
      " - 254s - loss: 0.4271 - acc: 0.7997 - val_loss: 0.4381 - val_acc: 0.7865\n",
      "Epoch 6/25\n",
      " - 306s - loss: 0.4092 - acc: 0.8105 - val_loss: 0.4618 - val_acc: 0.7672\n",
      "Epoch 7/25\n",
      " - 330s - loss: 0.3961 - acc: 0.8195 - val_loss: 0.4251 - val_acc: 0.7948\n",
      "Epoch 8/25\n",
      " - 332s - loss: 0.3837 - acc: 0.8261 - val_loss: 0.4200 - val_acc: 0.7976\n",
      "Epoch 9/25\n",
      " - 331s - loss: 0.3734 - acc: 0.8324 - val_loss: 0.4205 - val_acc: 0.8001\n",
      "Epoch 10/25\n",
      " - 328s - loss: 0.3628 - acc: 0.8372 - val_loss: 0.4152 - val_acc: 0.8023\n",
      "Epoch 11/25\n",
      " - 329s - loss: 0.3539 - acc: 0.8435 - val_loss: 0.4310 - val_acc: 0.7932\n",
      "Epoch 12/25\n",
      " - 328s - loss: 0.3433 - acc: 0.8487 - val_loss: 0.4119 - val_acc: 0.8047\n",
      "Epoch 13/25\n",
      " - 328s - loss: 0.3372 - acc: 0.8514 - val_loss: 0.4131 - val_acc: 0.8047\n",
      "Epoch 14/25\n",
      " - 328s - loss: 0.3299 - acc: 0.8562 - val_loss: 0.4152 - val_acc: 0.8001\n",
      "Epoch 15/25\n",
      " - 329s - loss: 0.3242 - acc: 0.8586 - val_loss: 0.4110 - val_acc: 0.8086\n",
      "Epoch 16/25\n",
      " - 328s - loss: 0.3193 - acc: 0.8614 - val_loss: 0.4211 - val_acc: 0.8010\n",
      "Epoch 17/25\n",
      " - 329s - loss: 0.3116 - acc: 0.8654 - val_loss: 0.4197 - val_acc: 0.8043\n",
      "Epoch 18/25\n",
      " - 328s - loss: 0.3060 - acc: 0.8681 - val_loss: 0.4117 - val_acc: 0.8061\n",
      "Epoch 19/25\n",
      " - 329s - loss: 0.3073 - acc: 0.8671 - val_loss: 0.4225 - val_acc: 0.7999\n",
      "Epoch 20/25\n",
      " - 330s - loss: 0.3015 - acc: 0.8706 - val_loss: 0.4150 - val_acc: 0.8057\n",
      "Epoch 21/25\n",
      " - 329s - loss: 0.2958 - acc: 0.8728 - val_loss: 0.4187 - val_acc: 0.8017\n",
      "Epoch 22/25\n",
      " - 329s - loss: 0.2932 - acc: 0.8737 - val_loss: 0.4218 - val_acc: 0.8047\n",
      "Epoch 23/25\n",
      " - 328s - loss: 0.2890 - acc: 0.8759 - val_loss: 0.4174 - val_acc: 0.8034\n",
      "Epoch 24/25\n",
      " - 327s - loss: 0.2862 - acc: 0.8777 - val_loss: 0.4123 - val_acc: 0.8069\n",
      "Epoch 25/25\n",
      " - 331s - loss: 0.2844 - acc: 0.8787 - val_loss: 0.4248 - val_acc: 0.8005\n",
      "Training ended at 2019-03-25 22:58:26.184670\n",
      "Minutes elapsed: 130.302667\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting training at\", datetime.datetime.now())\n",
    "t0 = time.time()\n",
    "\n",
    "#callback to store the best weights\n",
    "callbacks = [ModelCheckpoint(MODEL_WEIGHTS_FILE, monitor='val_acc', save_best_only=True)]\n",
    "\n",
    "history = model.fit([Q1_train, Q2_train],\n",
    "                    y_train,\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    validation_split=VALIDATION_SPLIT,\n",
    "                    verbose=2,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    callbacks=callbacks)\n",
    "t1 = time.time()\n",
    "print(\"Training ended at\", datetime.datetime.now())\n",
    "print(\"Minutes elapsed: %f\" % ((t1 - t0) / 60.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot training and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21218a9e438>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Data\n",
    "df=pd.DataFrame({'x': range(1,11), 'y1': np.random.randn(10), 'y2': np.random.randn(10)+range(1,11), 'y3': np.random.randn(10)+range(11,21) })\n",
    "acc = pd.DataFrame({'epoch': [ i + 1 for i in history.epoch ],\n",
    "                    'training': history.history['acc'],\n",
    "                    'validation': history.history['val_acc']}) \n",
    "# multiple line plot\n",
    "ax= plt.plot( 'epoch', 'training', data=acc,markersize=12, color='blue', linewidth=4)\n",
    "ax= plt.plot( 'epoch', 'validation', data=acc,markersize=12, color='red', linewidth=4)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print best validation accuracy and epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum accuracy at epoch 15 = 0.8086\n"
     ]
    }
   ],
   "source": [
    "max_val_acc, idx = max((val, idx) for (idx, val) in enumerate(history.history['val_acc']))\n",
    "print('Maximum accuracy at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(max_val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model with best validation accuracy on the test partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss = 0.4094, accuracy = 0.8091\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "loss, accuracy = model.evaluate([Q1_test, Q2_test], y_test, verbose=0)\n",
    "print('loss = {0:.4f}, accuracy = {1:.4f}'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing individual sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this section as a server for the Web Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, TimeDistributed, dot, Dense, Lambda, Flatten, concatenate, Dropout, BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import Callback, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_EMBEDDING_MATRIX_FILE = 'word_embedding_matrix.npy'\n",
    "NB_WORDS_DATA_FILE = 'nb_words.json'\n",
    "MODEL_WEIGHTS_FILE = 'question_pairs_weights_network2.h5'\n",
    "MAX_SEQUENCE_LENGTH = 25\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RNG_SEED = 13371447\n",
    "NB_EPOCHS = 25\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "with open(NB_WORDS_DATA_FILE, 'r') as f:\n",
    "    nb_words = json.load(f)['nb_words']\n",
    "    \n",
    "word_embedding_matrix = np.load(open(WORD_EMBEDDING_MATRIX_FILE, 'rb'))\n",
    "\n",
    "with open('word_index.pickle', 'rb') as handle:\n",
    "    word_indices = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_9/Sigmoid:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "question1 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "question2 = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "\n",
    "#layer 1 for question 1 to convert the sequence of vectors into dense representation\n",
    "q1 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question1)\n",
    "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
    "q1 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q1)\n",
    "q1 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q1)\n",
    "\n",
    "#layer 1 for question 2 to convert the sequence of vectors into dense representation\n",
    "q2 = Embedding(nb_words + 1, \n",
    "                 EMBEDDING_DIM, \n",
    "                 weights=[word_embedding_matrix], \n",
    "                 input_length=MAX_SEQUENCE_LENGTH, \n",
    "                 trainable=False)(question2)\n",
    "#We use time distributed layer to formulate the sequential nature of our words in the question\n",
    "q2 = TimeDistributed(Dense(EMBEDDING_DIM, activation='relu'))(q2)\n",
    "q2 = Lambda(lambda x: K.max(x, axis=1), output_shape=(EMBEDDING_DIM, ))(q2)\n",
    "\n",
    "#Concatenate the representations for question 1 and 2\n",
    "merged = concatenate([q1,q2])\n",
    "\n",
    "#dense layer 1\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 2\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 3\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 4\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 5\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "#dense layer 6\n",
    "merged = Dense(200, activation='relu')(merged)\n",
    "#to avoid overfitting\n",
    "merged = Dropout(DROPOUT)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "\n",
    "#final prediction using sigmoid activation\n",
    "is_duplicate = Dense(1, activation='sigmoid')(merged)\n",
    "print(is_duplicate)\n",
    "model = Model(inputs=[question1,question2], outputs=is_duplicate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec(question):\n",
    "    word_seq = keras.preprocessing.text.text_to_word_sequence(question)\n",
    "    \n",
    "    vec_sequence = [word_indices[w] for w in word_seq]\n",
    "    \n",
    "    vec_sequence = pad_sequences([vec_sequence], maxlen= 25)\n",
    "    return vec_sequence\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = 'Hi Im here waiting for you.where are you?'\n",
    "question2 = 'Hi what era is this?'\n",
    "\n",
    "model.load_weights(MODEL_WEIGHTS_FILE)\n",
    "predictions = model.predict([word2vec(question1), word2vec(question2)], verbose=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0143868]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
